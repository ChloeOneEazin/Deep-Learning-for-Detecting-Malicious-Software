# DEEP LEARNING FOR DETECTING MALICIOUS SOFTWARE

This repository contains the code, datasets, and documentation for the Final Year Project (FYP) titled Deep Learning for Detecting Malicious Software. The goal of this project is to leverage deep learning techniques including CNN, ResNet, Xception and Inception and transformer DeiT with Spatial Aggregation Vector Encoding (SAVE) to accurately classify malware images into benign or malicious categories.

---

## ğŸ“ Project Structure

.
Source Code/DEEP LEARNING FOR DETECTING MALICIOUS SOFTWARE/
â”œâ”€â”€ Source Code for Blended malware image/
â”‚   â”œâ”€â”€ DeiT with SAVE.ipynb
â”‚   â”œâ”€â”€ DeiT.ipynb
â”‚   â”œâ”€â”€ Inception with SAVE.ipynb
â”‚   â”œâ”€â”€ Inception.ipynb
â”‚   â”œâ”€â”€ ResNet 50 with SAVE.ipynb
â”‚   â”œâ”€â”€ ResNet.ipynb
â”‚   â”œâ”€â”€ Xception with SAVE.ipynb
â”‚   â””â”€â”€ Xception.ipynb
â”‚
â””â”€â”€ Source Code for Malware as Images/
    â”œâ”€â”€ DeiT SAVE.ipynb
    â”œâ”€â”€ DeiT.ipynb
    â”œâ”€â”€ Inception with SAVE.ipynb
    â”œâ”€â”€ Inception.ipynb
    â”œâ”€â”€ ResNet with SAVE.ipynb
    â”œâ”€â”€ ResNet.ipynb
    â”œâ”€â”€ Xception with SAVE.ipynb
    â””â”€â”€ Xception.ipynb


## ğŸ“‚ `code/` Folder

This directory contains all experiment-related files, including model training and prediction generation notebooks. It is organized into three subfolders: `Dataset1`, `Dataset2`, and `Dataset3`.

### ğŸ“Œ Contents

#### 1. **Blended Malware Image**

Location: Source Code/DEEP LEARNING FOR DETECTING MALICIOUS SOFTWARE/Source Code for Blended malware image/

Format: <Model>.ipynb and <Model> with SAVE.ipynb

Models Included:
DeiT & DeiT with SAVE
Inception & Inception with SAVE
ResNet 50 & ResNet 50 with SAVE
Xception & Xception with SAVE

Contents: Data loading via tf.data, model construction (backbone + SAVE layer), training with callbacks (best checkpoint), history plotting, validation & testing (classification report, confusion matrix), and final model export.

#### 2. **Malware as Images**

Location: Source Code/DEEP LEARNING FOR DETECTING MALICIOUS SOFTWARE/Source Code for Malware as Images/

Format: <Model>.ipynb and <Model> SAVE.ipynb

Models Included:
DeiT & DeiT SAVE
Inception & Inception with SAVE
ResNet & ResNet with SAVE
Xception & Xception with SAVE

Contents: Identical workflow as Blended notebooks, applied to the original Malware as Images dataset folder.


---

## ğŸ“‚ `dataset/` Folder

This folder includes all datasets used for model training and evaluation. All datasets were sourced from Kaggle and are provided in `.csv` format for convenience.

### ğŸ“Œ Datasets

1. **Blended Malware Image Dataset**  
   ğŸ“ https://www.kaggle.com/datasets/gauravpendharkar/blended-malware-image-dataset/data

2. **Malware as Images**  
   ğŸ“ https://www.kaggle.com/datasets/matthewfields/malware-as-images


---

## ğŸ’» Technologies Used

- Languages & Tools: Python, Jupyter Notebook
- Frameworks: TensorFlow/Keras, PyTorch (for baseline comparisons)
- Libraries: NumPy, pandas, scikit-learn, imbalanced-learn (SMOTE), matplotlib
- Hardware: NVIDIA GPU (CUDA)

---

## ğŸ“Š Task Overview

The primary objectives of this FYP are:

**1. Problem Statement: **Malware poses a significant security threat. Traditional signature-based detection methods struggle with new and obfuscated samples. Deep learning approaches can learn rich visual patterns from malware images, improving detection of novel variants.

**2. Goals:**
Convert raw malware binaries into grayscale images.
Implement and compare multiple architectures (ResNet50, InceptionV3, Xception, Custom CNN) enhanced with SAVE layers.
Integrate techniques such as SMOTE, data augmentation, batch normalization, L2 regularization, and dropout to address class imbalance and overfitting.
Evaluate models using classification metrics (accuracy, precision, recall, F1-score) and confusion matrices.

**3. Methodology:** Data preprocessing â†’ Model design â†’ Training and validation â†’ Prediction generation â†’ Performance analysis.

---


## ğŸ“œ License

This project is for academic and research purposes only. Datasets belong to their respective Kaggle  contributors.
