{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee089db",
   "metadata": {},
   "source": [
    "**DeiT without SAVE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19b1116",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd87f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Dense, Layer, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from vit_keras import vit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b7c6b",
   "metadata": {},
   "source": [
    "Dataset Configuration and Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b88a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"Blended malware image\"\n",
    "image_size = (224, 224)\n",
    "batch_size = 16\n",
    "\n",
    "classes = sorted(\n",
    "    d for d in os.listdir(source_dir)\n",
    "    if os.path.isdir(os.path.join(source_dir, d))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f3d07",
   "metadata": {},
   "source": [
    "Gather Files Path and Integer Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6095083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths, labels = [], []\n",
    "for label, cls in enumerate(classes):\n",
    "    cls_dir = os.path.join(source_dir, cls)\n",
    "    for fname in os.listdir(cls_dir):\n",
    "        fpath = os.path.join(cls_dir, fname)\n",
    "        if os.path.isfile(fpath):\n",
    "            file_paths.append(fpath)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e90bd48",
   "metadata": {},
   "source": [
    "Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34f5044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(file_paths, labels, test_size=0.30, stratify=labels, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f33511",
   "metadata": {},
   "source": [
    "TF-Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e354944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function process_path at 0x000002CF4CEA74C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function process_path at 0x000002CF4CEA74C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "def process_path(file_path, label):\n",
    "    img = tf.io.decode_jpeg(tf.io.read_file(file_path), channels=3)\n",
    "    img = tf.image.resize(img, image_size)\n",
    "    img = tf.keras.applications.imagenet_utils.preprocess_input(img)\n",
    "    label = tf.one_hot(label, depth=len(classes))\n",
    "    return img, label\n",
    "\n",
    "def make_dataset(X, y, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(X))\n",
    "    return (\n",
    "        ds\n",
    "        .map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "train_ds = make_dataset(X_train, y_train, shuffle=True)\n",
    "val_ds = make_dataset(X_val, y_val, shuffle=False)\n",
    "test_ds = make_dataset(X_test, y_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c52a4",
   "metadata": {},
   "source": [
    "DeiT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69f7d4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\vit_keras\\utils.py:83: UserWarning: Resizing position embeddings from 24, 24 to 14, 14\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " embedding (Conv2D)          (None, 14, 14, 768)       590592    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 196, 768)          0         \n",
      "                                                                 \n",
      " class_token (ClassToken)    (None, 197, 768)          768       \n",
      "                                                                 \n",
      " Transformer/posembed_input   (None, 197, 768)         151296    \n",
      " (AddPositionEmbs)                                               \n",
      "                                                                 \n",
      " Transformer/encoderblock_0   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_1   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_2   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_3   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_4   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_5   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_6   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_7   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_8   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_9   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_10  ((None, 197, 768),       7087872   \n",
      "  (TransformerBlock)          (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_11  ((None, 197, 768),       7087872   \n",
      "  (TransformerBlock)          (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoder_norm (L  (None, 197, 768)         1536      \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " fold_patches (Lambda)       (None, 14, 14, 768)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 150528)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              150529000 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 31)                31031     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 236,358,687\n",
      "Trainable params: 236,358,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_deit_model(num_classes, image_size=image_size, patch_size=16):\n",
    "    # Load pretrained ViT backbone\n",
    "    backbone = vit.vit_b16(\n",
    "        image_size=image_size,\n",
    "        pretrained=True,\n",
    "        include_top=False,\n",
    "        pretrained_top=False\n",
    "    )\n",
    "\n",
    "    # Extract sequence output before classification token\n",
    "    seq_output = backbone.get_layer(\"Transformer/encoder_norm\").output\n",
    "    seq_model  = Model(inputs=backbone.input, outputs=seq_output)\n",
    "\n",
    "    # Fold patch tokens into feature map\n",
    "    def fold_patches(x):\n",
    "        patch_tokens = x[:, 1:, :]\n",
    "        return tf.reshape(\n",
    "            patch_tokens,\n",
    "           (-1,\n",
    "             image_size[0] // patch_size,\n",
    "             image_size[1] // patch_size,\n",
    "             x.shape[-1])\n",
    "        )\n",
    "\n",
    "    x = Lambda(fold_patches, name=\"fold_patches\")(seq_model.output)\n",
    "\n",
    "    # Classification head\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1000, activation=\"relu\")(x)\n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=seq_model.input, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.AUC(name='auc'),\n",
    "            tf.keras.metrics.FalsePositives(name='false_positives'),\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall'),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_deit_model(num_classes=len(classes))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4270888",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c971e062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002CF4C16B558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002CF4C16B558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.6985 - accuracy: 0.8920 - auc: 0.9728 - false_positives: 642.0000 - precision: 0.9292 - recall: 0.8789 WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002CF4E7E85E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002CF4E7E85E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.85911, saving model to checkpoints\\vit_malware_best.h5\n",
      "300/300 [==============================] - 6752s 22s/step - loss: 1.6985 - accuracy: 0.8920 - auc: 0.9728 - false_positives: 642.0000 - precision: 0.9292 - recall: 0.8789 - val_loss: 0.8418 - val_accuracy: 0.8591 - val_auc: 0.9672 - val_false_positives: 54.0000 - val_precision: 0.9013 - val_recall: 0.8471\n",
      "Epoch 2/20\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9979 - auc: 0.9999 - false_positives: 17.0000 - precision: 0.9982 - recall: 0.9975 \n",
      "Epoch 2: val_accuracy improved from 0.85911 to 0.87629, saving model to checkpoints\\vit_malware_best.h5\n",
      "300/300 [==============================] - 6815s 23s/step - loss: 0.0077 - accuracy: 0.9979 - auc: 0.9999 - false_positives: 17.0000 - precision: 0.9982 - recall: 0.9975 - val_loss: 0.7844 - val_accuracy: 0.8763 - val_auc: 0.9671 - val_false_positives: 51.0000 - val_precision: 0.9076 - val_recall: 0.8608\n",
      "Epoch 3/20\n",
      "300/300 [==============================] - ETA: 0s - loss: 9.2193e-05 - accuracy: 1.0000 - auc: 1.0000 - false_positives: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 3: val_accuracy did not improve from 0.87629\n",
      "300/300 [==============================] - 6284s 21s/step - loss: 9.2193e-05 - accuracy: 1.0000 - auc: 1.0000 - false_positives: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7906 - val_accuracy: 0.8746 - val_auc: 0.9672 - val_false_positives: 51.0000 - val_precision: 0.9076 - val_recall: 0.8608\n",
      "Epoch 4/20\n",
      " 35/300 [==>...........................] - ETA: 1:38:16 - loss: 5.0268e-05 - accuracy: 1.0000 - auc: 1.0000 - false_positives: 0.0000e+00 - precision: 1.0000 - recall: 1.0000"
     ]
    }
   ],
   "source": [
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    filepath='checkpoints/vit_malware_best.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "train_ds_inf = make_dataset(X_train, y_train, shuffle=True) \\\n",
    "                   .repeat()  \n",
    "\n",
    "history = model.fit(\n",
    "    train_ds_inf,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=300,      \n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint_cb]\n",
    ")\n",
    "\n",
    "model.save('models/vit_malware_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ddce9",
   "metadata": {},
   "source": [
    "Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a702a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(hist):\n",
    "    metrics = ['loss', 'accuracy', 'auc', 'false_positives', 'precision', 'recall']\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(12, 12))\n",
    "    for idx, m in enumerate(metrics):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        ax.plot(hist.history[m], label='train')\n",
    "        ax.plot(hist.history[f'val_{m}'], label='val')\n",
    "        ax.set_title(m)\n",
    "        ax.set_xlabel('epoch')\n",
    "        ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3ccddb",
   "metadata": {},
   "source": [
    "Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679c720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = model.evaluate(val_ds, verbose=1)\n",
    "print(\"\\nValidation set metrics:\")\n",
    "for name, value in zip(model.metrics_names, val_metrics):\n",
    "    print(f\" - {name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cc77b9",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f13b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "preds = model.predict(test_ds)\n",
    "print(f\"\\nInference time on test set: {time.time() - start:.2f}s\")\n",
    "\n",
    "y_true = np.argmax(\n",
    "    np.vstack([y for _, y in test_ds.unbatch()]), axis=1\n",
    ")\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66262833",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd22ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.imshow(cm, interpolation='nearest', aspect='auto')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45, ha='right')\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# annotate each cell\n",
    "thresh = cm.max() / 2\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    plt.text(\n",
    "        j, i, f\"{cm[i, j]:d}\",\n",
    "        ha='center', va='center',\n",
    "        color='white' if cm[i, j] > thresh else 'black'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
